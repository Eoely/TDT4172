{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7b09f97e",
   "metadata": {},
   "source": [
    "## âš¡ Final Mission: Mapping SkyNet's Energy Nexus\n",
    "\n",
    "### ğŸŒ The Discovery\n",
    "SkyNet is harvesting energy from Trondheim's buildings. Some structures provide significantly more power than others.\n",
    "\n",
    "### ğŸ¯ Your Mission\n",
    "Predict the **Nexus Rating** of unknown buildings in Trondheim (test set).\n",
    "\n",
    "### ğŸ§  The Challenge\n",
    "1. **Target**: Transform the Nexus Rating to reveal true energy hierarchy\n",
    "2. **Data Quality**: Handle missing values and categorical features\n",
    "3. **Ensembling**: Use advanced models and ensemble learning\n",
    "\n",
    "### ğŸ’¡ Hint\n",
    "You suspect that an insider has tampered with the columns in the testing data... \n",
    "\n",
    "Compare the training and test distributions and try to rectify the test dataset.\n",
    "\n",
    "### ğŸ“Š Formal Requirements\n",
    "1. **Performance**: Achieve RMSLE <= 0.294 on the test set\n",
    "2. **Discussion**:\n",
    "\n",
    "   a. Explain your threshold-breaking strategy\n",
    "\n",
    "   b. Justify RMSLE usage. Why do we use this metric? Which loss function did you use?\n",
    "\n",
    "   c. Plot and interpret feature importances\n",
    "\n",
    "   d. Describe your ensembling techniques\n",
    "\n",
    "   e. In real life, you do not have the test targets. How would you make sure your model will work good on the unseen data? \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d3efa9b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "train = pd.read_csv('final_mission_train.csv')\n",
    "test = pd.read_csv('final_mission_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ec1554b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_log_error\n",
    "\n",
    "def rmsle(y_true, y_pred):\n",
    "    \"\"\" Root Mean Squared Logarithmic Error \"\"\"\n",
    "    return np.sqrt(mean_squared_log_error(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0b20dc06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shfit all colummns in the test set right by 1, except ownership type\n",
    "original_grid = test['grid_connections'].copy()\n",
    "copy = test.copy()\n",
    "test.iloc[:, 1:] = copy.iloc[:, 1:].shift(1, axis=1)\n",
    "test['nexus_rating'] = original_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a7875458",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ownership_type               0.379214\n",
       "nexus_rating                 0.000000\n",
       "energy_footprint             0.000000\n",
       "core_reactor_size            0.202749\n",
       "harvesting_space             0.166717\n",
       "vertical_alignment           0.000000\n",
       "power_chambers               0.000000\n",
       "shared_conversion_units      0.166287\n",
       "isolated_conversion_units    0.166287\n",
       "internal_collectors          0.346661\n",
       "external_collectors          0.346661\n",
       "grid_connections             0.003436\n",
       "dtype: float64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Data preprocessing - All resulting in worse results\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Identify continous & categorical columns\n",
    "# continous = train.nunique()[train.nunique() > 10].index.tolist()\n",
    "# categorical = train.nunique()[train.nunique() <= 10].index.tolist() # Should really use set theory\n",
    "\n",
    "# preprocess = ColumnTransformer([\n",
    "#     (\"num\", SimpleImputer(strategy=\"mean\"), continous),\n",
    "#     (\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), categorical),\n",
    "# ])\n",
    "\n",
    "# # Do fill strategy for continous\n",
    "# Maybe create a function?\n",
    "# test[continous] = test[continous].fillna(test[continous].mean())\n",
    "# train[continous] = train[continous].fillna(train[continous].mean())\n",
    "\n",
    "\n",
    "# #do fill strategy for categorical\n",
    "# train = train.apply(lambda x: x.fillna(x.value_counts().index[0]))\n",
    "# test = test.apply(lambda x: x.fillna(x.value_counts().index[0]))\n",
    "\n",
    "# # One hot encode categorical values\n",
    "# train = pd.get_dummies(train, columns=categorical, drop_first=True)\n",
    "# test = pd.get_dummies(test, columns=categorical, drop_first=True)\n",
    "\n",
    "# train.isnull().sum()\n",
    "# missing_percentage = test.isnull().sum() / len(test)\n",
    "# missing_percentage.keys\n",
    "threshold = 0.4\n",
    "missing_frac = train.isna().mean()   # fraction of NaNs per column\n",
    "keep_cols = missing_frac[missing_frac <= threshold].index\n",
    "\n",
    "train = train[keep_cols]\n",
    "test = test[keep_cols]\n",
    "train.isna().mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ef49bd54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF RAW    CV RMSLE: 0.322180 Â± 0.006347\n",
      "RF LOG1P  CV RMSLE: 0.311342 Â± 0.006670\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.compose import ColumnTransformer, TransformedTargetRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from sklearn.metrics import make_scorer, mean_squared_log_error\n",
    "\n",
    "# -----------------------------\n",
    "# Config\n",
    "# -----------------------------\n",
    "TARGET = \"nexus_rating\"\n",
    "cv = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# def rmsle(y_true, y_pred):\n",
    "#     y_pred = np.clip(np.asarray(y_pred), 0, None)\n",
    "#     return mean_squared_log_error(np.asarray(y_true), y_pred) ** 0.5\n",
    "\n",
    "rmsle_scorer = make_scorer(rmsle, greater_is_better=False)\n",
    "\n",
    "# -----------------------------\n",
    "# Split data\n",
    "# -----------------------------\n",
    "x_train = train.drop(columns=[TARGET]).copy()\n",
    "y_train = train[TARGET].astype(float).copy()\n",
    "x_test  = test.drop(columns=[TARGET], errors=\"ignore\").copy()\n",
    "\n",
    "# -----------------------------\n",
    "# Column inference (minimal)\n",
    "# - Only treat object/category as categorical\n",
    "# - Everything numeric stays numeric (no cardinality heuristics)\n",
    "# -----------------------------\n",
    "cat_cols = x_train.select_dtypes(include=[\"object\", \"category\"]).columns.tolist()\n",
    "num_cols = x_train.select_dtypes(include=[np.number]).columns.tolist()\n",
    "\n",
    "preprocess = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", SimpleImputer(strategy=\"median\"), num_cols),                 # robust, minimal\n",
    "        (\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), cat_cols),           # only for true string cats\n",
    "    ],\n",
    "    remainder=\"drop\",\n",
    ")\n",
    "\n",
    "# -----------------------------\n",
    "# Base RandomForest (solid defaults for tabular)\n",
    "# -----------------------------\n",
    "rf = RandomForestRegressor(\n",
    "    n_estimators=1000,\n",
    "    max_depth=None,\n",
    "    min_samples_leaf=3,        # smooths and helps tails\n",
    "    max_features=0.5,          # reduce tree correlation\n",
    "    n_jobs=-1,\n",
    "    random_state=42,\n",
    ")\n",
    "\n",
    "# -----------------------------\n",
    "# Variant A: Train on RAW target (clip only at scoring)\n",
    "# -----------------------------\n",
    "pipe_raw = Pipeline([\n",
    "    (\"prep\", preprocess),\n",
    "    (\"model\", rf),\n",
    "])\n",
    "\n",
    "# -----------------------------\n",
    "# Variant B: Train on LOG1P(target), invert with EXPM1 + clipâ‰¥0\n",
    "# -----------------------------\n",
    "def inv_expm1_clip(yhat_log):\n",
    "    return np.clip(np.expm1(yhat_log), 0, None)\n",
    "\n",
    "pipe_log = Pipeline([\n",
    "    (\"prep\", preprocess),\n",
    "    (\"model\", TransformedTargetRegressor(\n",
    "        regressor=rf,\n",
    "        func=np.log1p,\n",
    "        inverse_func=inv_expm1_clip,\n",
    "        check_inverse=False,\n",
    "    )),\n",
    "])\n",
    "\n",
    "# -----------------------------\n",
    "# Cross-validated comparison (RMSLE)\n",
    "# -----------------------------\n",
    "scores_raw = -cross_val_score(pipe_raw, x_train, y_train, cv=cv, scoring=rmsle_scorer, n_jobs=-1)\n",
    "scores_log = -cross_val_score(pipe_log, x_train, y_train, cv=cv, scoring=rmsle_scorer, n_jobs=-1)\n",
    "\n",
    "print(f\"RF RAW    CV RMSLE: {scores_raw.mean():.6f} Â± {scores_raw.std():.6f}\")\n",
    "print(f\"RF LOG1P  CV RMSLE: {scores_log.mean():.6f} Â± {scores_log.std():.6f}\")\n",
    "\n",
    "# -----------------------------\n",
    "# Fit the better one and predict\n",
    "# -----------------------------\n",
    "best_pipe = pipe_log if scores_log.mean() <= scores_raw.mean() else pipe_raw\n",
    "best_pipe.fit(x_train, y_train)\n",
    "\n",
    "y_pred = best_pipe.predict(x_test)  # already non-negative in LOG1P case; RAW may need clipping if you compute RMSLE\n",
    "y_pred_safe = np.clip(y_pred, 0, None)\n",
    "\n",
    "rf_fit = rf.fit(x_train, y_train)\n",
    "y_pred_ez = rf.predict(x_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ced91df8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Most important column by far is energy_consumption\n",
    "# What does that mean, and how to fix\n",
    "# print(len(x_train.columns.tolist()), len(rf.feature_importances_))\n",
    "# test = zip(x_train.columns.tolist(), rf.feature_importances_)\n",
    "# tuple(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "769f8a3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Required RMSLE:  0.294\n",
      "RMSLE:  0.32589298204940365\n",
      "RMSLE:  0.3345966358547679\n"
     ]
    }
   ],
   "source": [
    "# Convert back the nexus_rating for a fair comparison\n",
    "\n",
    "print('Required RMSLE: ', 0.294)\n",
    "print('RMSLE: ', rmsle(test['nexus_rating'], y_pred_safe))\n",
    "\n",
    "print('RMSLE: ', rmsle(test['nexus_rating'], y_pred_ez))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tdt4172",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
